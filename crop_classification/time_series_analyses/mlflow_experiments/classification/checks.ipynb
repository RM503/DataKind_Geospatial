{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sktime.datatypes import check_is_scitype\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sktime.transformations.panel.catch22 import Catch22\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, cohen_kappa_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(df: pd.DataFrame, df_label: pd.DataFrame) -> pd.DataFrame:\n",
    "    if \"Unnamed: 0\" in df.columns:\n",
    "        df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "\n",
    "    # If labeled data does not contain all polygons\n",
    "    missing_uuid = list(set(df[\"uuid\"].unique()) - set(df_label[\"uuid\"].unique()))\n",
    "\n",
    "    if len(missing_uuid) > 0:\n",
    "        df = df[~df[\"uuid\"].isin(missing_uuid)]\n",
    "\n",
    "    # Transform data into sktime scitype and check\n",
    "    df_transformed = df.set_index([\"uuid\", \"date\"])[[\"ndvi\"]]\n",
    "    type_check = check_is_scitype(\n",
    "        df_transformed,\n",
    "        scitype=\"Panel\",\n",
    "        return_metadata=True\n",
    "    )\n",
    "\n",
    "    if type_check[0]:\n",
    "        print(f\"Dataframe has correct 'scitype': {type_check[2]['scitype']}\")\n",
    "        return df_transformed\n",
    "    else:\n",
    "        print(f\"Dataframe does not have the correct 'scitype': {type_check[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe has correct 'scitype': Panel\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"/Users/rafidmahbub/Desktop/DataKind_Geospatial/crop_classification/time_series_analyses/ndvi_series_labeled/Trans_Nzoia_1_ndvi_train.csv\"\n",
    "LABEL_PATH = \"/Users/rafidmahbub/Desktop/DataKind_Geospatial/crop_classification/time_series_analyses/ndvi_series_labeled/Trans_Nzoia_1_label_train.csv\"\n",
    "    \n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df_label = pd.read_csv(LABEL_PATH)\n",
    "\n",
    "df_label[\"class_encoded\"] = df_label[\"class\"].astype(\"category\").cat.codes\n",
    "\n",
    "df_transformed = transform_data(df, df_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RemoveNaNColumns(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self):\n",
    "        self.columns_to_drop = None\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        # Validate data type\n",
    "        X = self._validate_input(X)\n",
    "        # Identify columns where all elements are NaN\n",
    "        nan_cols = np.where(np.all(np.isnan(X), axis=0))[0]\n",
    "        self.columns_to_drop = nan_cols \n",
    "\n",
    "        return self \n",
    "    def transform(self, X):\n",
    "        # Drop columns\n",
    "        X_transformed = np.delete(X, self.columns_to_drop, axis=1)\n",
    "\n",
    "        return X_transformed\n",
    "    \n",
    "    def _validate_input(self, X):\n",
    "        if isinstance(X, np.ndarray):\n",
    "            return X \n",
    "        else:\n",
    "            raise TypeError(\"Object X does not have the required Numpy array format.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rafidmahbub/Desktop/DataKind_Geospatial/env/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy for fold 1: 0.8303655107778819\n",
      "validation class 0 f1 for fold 1: 0.908881199538639\n",
      "validation kappa score for fold 1: 0.7497155372393505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rafidmahbub/Desktop/DataKind_Geospatial/env/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy for fold 2: 0.8153701968134958\n",
      "validation class 0 f1 for fold 2: 0.9082672706681767\n",
      "validation kappa score for fold 2: 0.7263810532947679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rafidmahbub/Desktop/DataKind_Geospatial/env/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy for fold 3: 0.8359887535145267\n",
      "validation class 0 f1 for fold 3: 0.9205607476635514\n",
      "validation kappa score for fold 3: 0.7585732516359094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rafidmahbub/Desktop/DataKind_Geospatial/env/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy for fold 4: 0.8227016885553471\n",
      "validation class 0 f1 for fold 4: 0.9072164948453608\n",
      "validation kappa score for fold 4: 0.7379653341275592\n",
      "validation accuracy for fold 5: 0.8339587242026266\n",
      "validation class 0 f1 for fold 5: 0.9195402298850575\n",
      "validation kappa score for fold 5: 0.7559204951910328\n",
      "Mean validation accuracy: 0.8276769747727757\n",
      "Mean validation class 0 f1 score: 0.912893188520157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rafidmahbub/Desktop/DataKind_Geospatial/env/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "uuids = df_label[\"uuid\"].values\n",
    "labels = df_label[\"class_encoded\"].values\n",
    "\n",
    "SKF = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "val_accuracies = []\n",
    "val_f1_scores = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(SKF.split(uuids, labels)):\n",
    "    train_ids = uuids[train_idx]\n",
    "    val_ids = uuids[val_idx]\n",
    "\n",
    "    # Filtering the multi-index dataframe\n",
    "    X_train = df_transformed.loc[\n",
    "        df_transformed.index.get_level_values(\"uuid\").isin(train_ids)\n",
    "    ]\n",
    "\n",
    "    X_test = df_transformed.loc[\n",
    "        df_transformed.index.get_level_values(\"uuid\").isin(val_ids)\n",
    "    ]\n",
    "\n",
    "    y_train = df_label.loc[df_label[\"uuid\"].isin(train_ids), \"class_encoded\"]\n",
    "    y_test = df_label.loc[df_label[\"uuid\"].isin(val_ids), \"class_encoded\"]\n",
    "\n",
    "    p = Pipeline(\n",
    "        [\n",
    "            (\"catch22\", Catch22()),\n",
    "            (\"minmax\", MinMaxScaler()),\n",
    "            (\"remove_nan\", RemoveNaNColumns()), \n",
    "            (\"imputer\", SimpleImputer(strategy=\"mean\"))\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    X_train_transformed = p.fit_transform(X_train)\n",
    "    X_test_transformed = p.transform(X_test)\n",
    "\n",
    "    clf_svc = SVC(\n",
    "        gamma=\"auto\",\n",
    "        class_weight=None,\n",
    "        C=968.6191736411615,\n",
    "        kernel=\"poly\",\n",
    "        probability=True\n",
    "    )\n",
    "    clf_lgb = LGBMClassifier(\n",
    "        verbosity=-1,\n",
    "        lambda_l1=6.534846895156005,\n",
    "        max_depth=9,\n",
    "        min_child_weight=0.3426063538482019,\n",
    "        learning_rate=0.05615369822555346,\n",
    "        bagging_freq=8,\n",
    "        min_child_samples=73,\n",
    "        lambda_l2=0.11610557699921975,\n",
    "        feature_fraction=0.5001440442609598,\n",
    "        num_leaves=209,\n",
    "        min_split_gain=0.10462928402523397,\n",
    "        bagging_fraction=0.9824426936456173\n",
    "    )\n",
    "    clf_xgb = XGBClassifier(\n",
    "        reg_lambda=3.5161512825735066,\n",
    "        max_delta_step=1.9115702476973047,\n",
    "        colsample_bylevel=0.9266123974934999,\n",
    "        max_depth=10,\n",
    "        learning_rate=0.18184576490542836,\n",
    "        objective=\"multi:softmax\",\n",
    "        min_split_loss=2.291361972153634,\n",
    "        n_estimators=105,\n",
    "        colsample_bytree=0.8851986960927963,\n",
    "        reg_alpha=2.411345757878557,\n",
    "        subsample=0.8161397597180512\n",
    "    )\n",
    "    clf_mlp = MLPClassifier(\n",
    "        learning_rate=\"adaptive\",\n",
    "        activation=\"relu\",\n",
    "        solver=\"adam\",\n",
    "        max_iter=692,\n",
    "        alpha=0.004081719188194644,\n",
    "        hidden_layer_sizes=46\n",
    "    )\n",
    "\n",
    "    clf_voting = VotingClassifier(\n",
    "        estimators=[\n",
    "            (\"SVC\", clf_svc),\n",
    "            (\"MLP\", clf_mlp),\n",
    "            (\"LGB\", clf_lgb),\n",
    "            (\"XGB\", clf_xgb)\n",
    "        ],\n",
    "        weights=[3, 2, 1, 1],\n",
    "        voting=\"hard\"\n",
    "    )\n",
    "\n",
    "    clf_voting.fit(X_train_transformed, y_train)\n",
    "    y_test_preds = clf_voting.predict(X_test_transformed)\n",
    "\n",
    "    val_accuracy = accuracy_score(y_test, y_test_preds)\n",
    "    print(f\"validation accuracy for fold {fold+1}: {val_accuracy}\")\n",
    "\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "    val_f1_score = f1_score(y_test, y_test_preds, labels=[0], average=\"weighted\")\n",
    "    print(f\"validation class 0 f1 for fold {fold+1}: {val_f1_score}\")\n",
    "\n",
    "    val_kappa = cohen_kappa_score(y_test, y_test_preds)\n",
    "    print(f\"validation kappa score for fold {fold+1}: {val_kappa}\")\n",
    "\n",
    "    val_f1_scores.append(val_f1_score)\n",
    "\n",
    "print(f\"Mean validation accuracy: {np.mean(val_accuracies)}\")\n",
    "print(f\"Mean validation class 0 f1 score: {np.mean(val_f1_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
