{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sktime.datatypes import check_is_scitype\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sktime.transformations.panel.catch22 import Catch22\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(df: pd.DataFrame, df_label: pd.DataFrame) -> pd.DataFrame:\n",
    "    if \"Unnamed: 0\" in df.columns:\n",
    "        df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "\n",
    "    # If labeled data does not contain all polygons\n",
    "    missing_uuid = list(set(df[\"uuid\"].unique()) - set(df_label[\"uuid\"].unique()))\n",
    "\n",
    "    if len(missing_uuid) > 0:\n",
    "        df = df[~df[\"uuid\"].isin(missing_uuid)]\n",
    "\n",
    "    # Transform data into sktime scitype and check\n",
    "    df_transformed = df.set_index([\"uuid\", \"date\"])[[\"ndvi\"]]\n",
    "    type_check = check_is_scitype(\n",
    "        df_transformed,\n",
    "        scitype=\"Panel\",\n",
    "        return_metadata=True\n",
    "    )\n",
    "\n",
    "    if type_check[0]:\n",
    "        print(f\"Dataframe has correct 'scitype': {type_check[2]['scitype']}\")\n",
    "        return df_transformed\n",
    "    else:\n",
    "        print(f\"Dataframe does not have the correct 'scitype': {type_check[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe has correct 'scitype': Panel\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"/Users/rafidmahbub/Desktop/DataKind_Geospatial/crop_classification/time_series_analyses/ndvi_series_labeled/ndvi_series_Trans_Nzoia_1_clean.csv\"\n",
    "LABEL_PATH = \"/Users/rafidmahbub/Desktop/DataKind_Geospatial/crop_classification/time_series_analyses/ndvi_series_labeled/ndvi_Trans_Nzoia_1_labels.csv\"\n",
    "    \n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df_label = pd.read_csv(LABEL_PATH)\n",
    "\n",
    "df_label[\"class_encoded\"] = df_label[\"class\"].astype(\"category\").cat.codes\n",
    "\n",
    "df_transformed = transform_data(df, df_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RemoveNaNColumns(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self):\n",
    "        self.columns_to_drop = None\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        # Validate data type\n",
    "        X = self._validate_input(X)\n",
    "        # Identify columns where all elements are NaN\n",
    "        nan_cols = np.where(np.all(np.isnan(X), axis=0))[0]\n",
    "        self.columns_to_drop = nan_cols \n",
    "\n",
    "        return self \n",
    "    def transform(self, X):\n",
    "        # Drop columns\n",
    "        X_transformed = np.delete(X, self.columns_to_drop, axis=1)\n",
    "\n",
    "        return X_transformed\n",
    "    \n",
    "    def _validate_input(self, X):\n",
    "        if isinstance(X, np.ndarray):\n",
    "            return X \n",
    "        else:\n",
    "            raise TypeError(\"Object X does not have the required Numpy array format.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy for fold 1: 0.8088426527958388\n",
      "validation class 0 f1 for fold 1: 0.9060955518945635\n",
      "validation accuracy for fold 2: 0.8153446033810143\n",
      "validation class 0 f1 for fold 2: 0.9015025041736227\n",
      "validation accuracy for fold 3: 0.811443433029909\n",
      "validation class 0 f1 for fold 3: 0.8943894389438944\n",
      "validation accuracy for fold 4: 0.8166449934980494\n",
      "validation class 0 f1 for fold 4: 0.9198717948717947\n",
      "validation accuracy for fold 5: 0.8046875\n",
      "validation class 0 f1 for fold 5: 0.9078498293515358\n",
      "Mean validation accuracy: 0.8113926365409622\n",
      "Mean validation class 0 f1 score: 0.9059418238470822\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "n_classes=4\n",
    "precision = {i: [] for i in range(n_classes)}\n",
    "recall = {i: [] for i in range(n_classes)}\n",
    "threshold = {i: [] for i in range(n_classes)}\n",
    "\n",
    "uuids = df_label[\"uuid\"].values\n",
    "labels = df_label[\"class_encoded\"].values\n",
    "\n",
    "SKF = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "val_accuracies = []\n",
    "val_f1_scores = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(SKF.split(uuids, labels)):\n",
    "    train_ids = uuids[train_idx]\n",
    "    val_ids = uuids[val_idx]\n",
    "\n",
    "    # Filtering the multi-index dataframe\n",
    "    X_train = df_transformed.loc[\n",
    "        df_transformed.index.get_level_values(\"uuid\").isin(train_ids)\n",
    "    ]\n",
    "\n",
    "    X_test = df_transformed.loc[\n",
    "        df_transformed.index.get_level_values(\"uuid\").isin(val_ids)\n",
    "    ]\n",
    "\n",
    "    y_train = df_label.loc[df_label[\"uuid\"].isin(train_ids), \"class_encoded\"]\n",
    "    y_test = df_label.loc[df_label[\"uuid\"].isin(val_ids), \"class_encoded\"]\n",
    "\n",
    "    p = Pipeline(\n",
    "        [\n",
    "            (\"catch22\", Catch22()),\n",
    "            (\"minmax\", MinMaxScaler()),\n",
    "            (\"remove_nan\", RemoveNaNColumns()), \n",
    "            (\"imputer\", SimpleImputer(strategy=\"mean\"))\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    X_train_transformed = p.fit_transform(X_train)\n",
    "    X_test_transformed = p.transform(X_test)\n",
    "\n",
    "    # select_k = SelectKBest(k=10, score_func=mutual_info_classif)\n",
    "    # X_train_k = select_k.fit_transform(X_train_transformed, y_train)\n",
    "    # X_test_k = select_k.transform(X_test_transformed)\n",
    "\n",
    "    clf = SVC().fit(X_train_transformed, y_train)\n",
    "    y_test_preds = clf.predict(X_test_transformed)\n",
    "\n",
    "    val_accuracy = accuracy_score(y_test, y_test_preds)\n",
    "    print(f\"validation accuracy for fold {fold+1}: {val_accuracy}\")\n",
    "\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "    val_f1_score = f1_score(y_test, y_test_preds, labels=[0], average=\"weighted\")\n",
    "    print(f\"validation class 0 f1 for fold {fold+1}: {val_f1_score}\")\n",
    "\n",
    "    val_f1_scores.append(val_f1_score)\n",
    "\n",
    "print(f\"Mean validation accuracy: {np.mean(val_accuracies)}\")\n",
    "print(f\"Mean validation class 0 f1 score: {np.mean(val_f1_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
